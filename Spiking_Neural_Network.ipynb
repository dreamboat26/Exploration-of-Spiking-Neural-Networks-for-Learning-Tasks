{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "0OJ8mf11ubH9",
        "outputId": "d87675d9-3f81-4065-eed1-eb44b833a3d9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# Network parameters\n",
        "# -------------------------------\n",
        "N_input = 100\n",
        "N_hidden = 50\n",
        "N_output = 10\n",
        "sim_time = 500  # ms\n",
        "dt = 1\n",
        "time_steps = int(sim_time / dt)\n",
        "\n",
        "# -------------------------------\n",
        "# Neuron parameters\n",
        "# -------------------------------\n",
        "v_rest = -65.0\n",
        "v_thresh = -58.0  # Lowered threshold\n",
        "tau = 10.0\n",
        "refractory_period = 5\n",
        "\n",
        "# -------------------------------\n",
        "# Input generation: high rate\n",
        "# -------------------------------\n",
        "input_rate = 100 / 1000  # 100 Hz\n",
        "input_spikes = np.random.rand(N_input, time_steps) < input_rate\n",
        "\n",
        "# -------------------------------\n",
        "# Initial voltage & refractory\n",
        "# -------------------------------\n",
        "v_hidden = np.full(N_hidden, v_rest)\n",
        "v_output = np.full(N_output, v_rest)\n",
        "ref_hidden = np.zeros(N_hidden)\n",
        "ref_output = np.zeros(N_output)\n",
        "\n",
        "# -------------------------------\n",
        "# Synaptic weights (stronger)\n",
        "# -------------------------------\n",
        "w_in_hidden = np.random.rand(N_input, N_hidden) * 2.0\n",
        "w_hidden_out = np.random.rand(N_hidden, N_output) * 4.0 + 2.0\n",
        "\n",
        "# -------------------------------\n",
        "# R-STDP learning\n",
        "# -------------------------------\n",
        "eta = 0.01\n",
        "tau_pre = 20\n",
        "tau_post = 20\n",
        "reward = 1.0\n",
        "pre_in_hidden = np.zeros((N_input, N_hidden))\n",
        "post_in_hidden = np.zeros((N_input, N_hidden))\n",
        "pre_hidden_out = np.zeros((N_hidden, N_output))\n",
        "post_hidden_out = np.zeros((N_hidden, N_output))\n",
        "\n",
        "# -------------------------------\n",
        "# Logging\n",
        "# -------------------------------\n",
        "hidden_spikes = []\n",
        "output_spikes = []\n",
        "\n",
        "# -------------------------------\n",
        "# Neuron update\n",
        "# -------------------------------\n",
        "def lif(v, I, ref):\n",
        "    ref_active = ref > 0\n",
        "    v[ref_active] = v_rest\n",
        "    v[~ref_active] += ((-v[~ref_active] + v_rest + I[~ref_active]) / tau)\n",
        "    spiked = v >= v_thresh\n",
        "    ref[spiked] = refractory_period\n",
        "    v[spiked] = v_rest\n",
        "    ref -= 1\n",
        "    return v, spiked, ref\n",
        "\n",
        "# -------------------------------\n",
        "# Simulation\n",
        "# -------------------------------\n",
        "for t in range(time_steps):\n",
        "    # Input → Hidden\n",
        "    spikes_input = input_spikes[:, t]\n",
        "    I_hidden = np.dot(spikes_input.astype(float), w_in_hidden)\n",
        "    v_hidden, s_hidden, ref_hidden = lif(v_hidden, I_hidden, ref_hidden)\n",
        "    hidden_spikes.append(s_hidden.copy())\n",
        "\n",
        "    # Hidden → Output\n",
        "    I_output = np.dot(s_hidden.astype(float), w_hidden_out)\n",
        "    v_output, s_output, ref_output = lif(v_output, I_output, ref_output)\n",
        "    output_spikes.append(s_output.copy())\n",
        "\n",
        "    # R-STDP: Input → Hidden\n",
        "    pre_in_hidden *= np.exp(-1 / tau_pre)\n",
        "    post_in_hidden *= np.exp(-1 / tau_post)\n",
        "    for i in range(N_input):\n",
        "        for j in range(N_hidden):\n",
        "            if spikes_input[i]:\n",
        "                pre_in_hidden[i, j] += 1\n",
        "                w_in_hidden[i, j] += eta * reward * post_in_hidden[i, j]\n",
        "            if s_hidden[j]:\n",
        "                post_in_hidden[i, j] += 1\n",
        "                w_in_hidden[i, j] += eta * reward * pre_in_hidden[i, j]\n",
        "            w_in_hidden[i, j] = np.clip(w_in_hidden[i, j], 0, 2.0)\n",
        "\n",
        "    # R-STDP: Hidden → Output\n",
        "    pre_hidden_out *= np.exp(-1 / tau_pre)\n",
        "    post_hidden_out *= np.exp(-1 / tau_post)\n",
        "    for i in range(N_hidden):\n",
        "        for j in range(N_output):\n",
        "            if s_hidden[i]:\n",
        "                pre_hidden_out[i, j] += 1\n",
        "                w_hidden_out[i, j] += eta * reward * post_hidden_out[i, j]\n",
        "            if s_output[j]:\n",
        "                post_hidden_out[i, j] += 1\n",
        "                w_hidden_out[i, j] += eta * reward * pre_hidden_out[i, j]\n",
        "            w_hidden_out[i, j] = np.clip(w_hidden_out[i, j], 0, 2.0)\n",
        "\n",
        "# -------------------------------\n",
        "# Visualization\n",
        "# -------------------------------\n",
        "hidden_spikes = np.array(hidden_spikes).T\n",
        "output_spikes = np.array(output_spikes).T\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Hidden Layer Spikes')\n",
        "for i in range(N_hidden):\n",
        "    times = np.where(hidden_spikes[i])[0]\n",
        "    plt.plot(times, [i]*len(times), '.r')\n",
        "plt.xlabel('Time (ms)')\n",
        "plt.ylabel('Neuron Index')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Output Layer Spikes')\n",
        "for i in range(N_output):\n",
        "    times = np.where(output_spikes[i])[0]\n",
        "    plt.plot(times, [i]*len(times), '.b')\n",
        "plt.xlabel('Time (ms)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KIyNzNP3Rfp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_spike_pattern(label, time_steps=300, shape=(34, 34), noise_level=0.01):\n",
        "    np.random.seed(label)  # deterministic patterns per class\n",
        "    base_pattern = np.random.rand(*shape) < 0.05  # sparse base\n",
        "\n",
        "    spike_tensor = np.zeros((time_steps, *shape))\n",
        "    for t in range(time_steps):\n",
        "        if t % 10 == 0:  # periodic spiking for structure\n",
        "            spike_tensor[t][base_pattern] = 1\n",
        "\n",
        "        # add noise\n",
        "        noise = np.random.rand(*shape) < noise_level\n",
        "        spike_tensor[t][noise] = 1\n",
        "\n",
        "    return spike_tensor.reshape(time_steps, -1)  # (T, 1156)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in6OpMiy3TxF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SNN:\n",
        "    def __init__(self, input_size=1156, hidden_size=100, output_size=3):\n",
        "        self.W1 = np.random.rand(input_size, hidden_size) * 0.5\n",
        "        self.W2 = np.random.rand(hidden_size, output_size) * 0.5\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def lif_layer(self, input_spikes, V, spikes, tau=20.0, v_th=1.0):\n",
        "        V = V * np.exp(-1 / tau) + input_spikes\n",
        "        spiked = V >= v_th\n",
        "        V[spiked] = 0\n",
        "        spikes[spiked] = 1\n",
        "        return V, spikes\n",
        "\n",
        "    def forward(self, inputs):  # (T, 1156)\n",
        "        T = inputs.shape[0]\n",
        "        hidden_spikes = np.zeros((T, self.hidden_size))\n",
        "        output_spikes = np.zeros((T, self.output_size))\n",
        "        V1 = np.zeros(self.hidden_size)\n",
        "        V2 = np.zeros(self.output_size)\n",
        "\n",
        "        for t in range(T):\n",
        "            input_t = inputs[t]\n",
        "            hidden_input = input_t @ self.W1\n",
        "            V1, s1 = self.lif_layer(hidden_input, V1, np.zeros_like(V1))\n",
        "            hidden_spikes[t] = s1\n",
        "\n",
        "            output_input = s1 @ self.W2\n",
        "            V2, s2 = self.lif_layer(output_input, V2, np.zeros_like(V2))\n",
        "            output_spikes[t] = s2\n",
        "\n",
        "        return hidden_spikes, output_spikes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFxPEP3A3V0y"
      },
      "outputs": [],
      "source": [
        "def reward_modulated_stdp(W, pre_spikes, post_spikes, reward, lr=0.01):\n",
        "    for t in range(len(pre_spikes)):\n",
        "        dw = np.outer(pre_spikes[t], post_spikes[t])\n",
        "        W += lr * reward * dw\n",
        "    return W\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dQATzDR3X4S",
        "outputId": "9f01a9d5-3364-4fd9-e5c9-ad414f53dd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1: Accuracy = 1/3\n",
            "Episode 2: Accuracy = 1/3\n",
            "Episode 3: Accuracy = 1/3\n",
            "Episode 4: Accuracy = 1/3\n",
            "Episode 5: Accuracy = 1/3\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = [0, 1, 2]\n",
        "model = SNN()\n",
        "\n",
        "for episode in range(5):\n",
        "    support = [(generate_spike_pattern(lbl), lbl) for lbl in labels for _ in range(5)]\n",
        "    query = [(generate_spike_pattern(lbl), lbl) for lbl in labels]\n",
        "\n",
        "    dw_total = np.zeros_like(model.W2)\n",
        "    for spikes, lbl in support:\n",
        "        h, o = model.forward(spikes)\n",
        "        pred = np.argmax(o.sum(axis=0))\n",
        "        reward = 1.0 if pred == lbl else -0.2\n",
        "        dw_total += reward * np.einsum(\"ti,tj->ij\", h, o)\n",
        "    model.W2 += 0.01 * dw_total\n",
        "\n",
        "    # 🧪 Evaluate on query set\n",
        "    correct = 0\n",
        "    for spikes, lbl in query:\n",
        "        _, o = model.forward(spikes)\n",
        "        pred = np.argmax(o.sum(axis=0))\n",
        "        correct += (pred == lbl)\n",
        "    print(f\"Episode {episode+1}: Accuracy = {correct}/3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcEcDOMB3ddN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_spike_raster(spikes, title):\n",
        "    times, neurons = np.where(spikes)\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.scatter(times, neurons, s=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Neuron\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLExw1626KxV",
        "outputId": "62147be3-c03a-47ac-a24f-37e85651bda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tonic\n",
            "  Downloading tonic-1.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting numpy<2.0.0 (from tonic)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from tonic) (3.13.0)\n",
            "Collecting importRosbag>=1.0.4 (from tonic)\n",
            "  Downloading importRosbag-1.0.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tonic) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tonic) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tonic) (4.13.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from tonic) (0.11.0)\n",
            "Collecting pbr (from tonic)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting expelliarmus (from tonic)\n",
            "  Downloading expelliarmus-1.1.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from importRosbag>=1.0.4->tonic) (75.2.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tonic) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa->tonic) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->tonic) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->tonic) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->tonic) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->tonic) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->tonic) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic) (2025.4.26)\n",
            "Downloading tonic-1.6.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading expelliarmus-1.1.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pbr, numpy, importRosbag, expelliarmus, tonic\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed expelliarmus-1.1.12 importRosbag-1.0.4 numpy-1.26.4 pbr-6.1.1 tonic-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tonic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "rw14PlW_6vqR",
        "outputId": "830b95d0-30e0-4d17-bdb4-716d7cb5b5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 2.2.6\n",
            "Uninstalling numpy-2.2.6:\n",
            "  Successfully uninstalled numpy-2.2.6\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.3 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b43ae28665304c4994292c55b7989f87",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.24.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "5b803c4395444d639a08999970a5a42b",
            "4c5528ebef5d4f6db3f9f68a5625fab3",
            "b5072050079d4e6ca576dc1a4098111a",
            "24acb4fe799645568f1ef38721a860bf",
            "0a47b0479a694dc88e4e24a63694af7f",
            "5f4f329bffa24dd98f98fa3ba7b9b51b",
            "5d2f0cc7c8b540d39865af53a8c24193",
            "5313a7f5d97c42509fec571283821a41",
            "745121e8201b4fbb90b6373a3ead3ea4",
            "9a0e1a577e944241bcd585d1aca3e231",
            "b0d0d0a478ad4e10a40b28d0c6b54146",
            "f53f11ba0897465396a099ce1ab81fa5",
            "85c0aab1c3ad43e1a349aef7740ac161",
            "758823e27cc24763aef595d8974ee947",
            "872265ce411b4abf816095a70c4e604a",
            "3699f65e94014c9d83cd9ab7d5c6eef6",
            "513f3a2a3f314666913b1d4066757da0",
            "2c0e0b1e54ba4949afaa3dfed8872273",
            "19fdd4cb0721478499d0f8cec4bdc310",
            "72c8eb82204a4514804853d28d980b74",
            "d4c17ae1eba34263ab6732ca479fddd3",
            "52ccc4f319c74918ad301e41d4b01a37"
          ]
        },
        "id": "POipEf4p6RPW",
        "outputId": "4d9a0608-988a-4562-b496-8569ff14f86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to ./data/NMNIST/train.zip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b803c4395444d639a08999970a5a42b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1011893601 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/NMNIST/train.zip to ./data/NMNIST\n",
            "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411 to ./data/NMNIST/test.zip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f53f11ba0897465396a099ce1ab81fa5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/169674850 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/NMNIST/test.zip to ./data/NMNIST\n"
          ]
        }
      ],
      "source": [
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from tonic import datasets\n",
        "\n",
        "transform = transforms.ToFrame(sensor_size=(34, 34, 2), time_window=1000)\n",
        "\n",
        "trainset = datasets.NMNIST(save_to='./data', train=True, transform=transform)\n",
        "testset = datasets.NMNIST(save_to='./data', train=False, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GVoJ2jg8-fO",
        "outputId": "6e02b48c-5d3b-4c3a-b01c-a1dfebc941e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering classes... (this may take a moment)\n",
            "Support set: 15 samples\n",
            "Query set: 30 samples\n",
            "Support sample shape: (1223, 2, 34, 34), label: 0\n"
          ]
        }
      ],
      "source": [
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from tonic import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "\n",
        "selected_classes = [0, 1, 2]\n",
        "sensor_size = (34, 34, 2)\n",
        "transform = transforms.ToFrame(sensor_size=sensor_size, time_window=250)\n",
        "\n",
        "full_dataset = datasets.NMNIST(save_to='./data', train=True, transform=transform)\n",
        "\n",
        "print(\"Filtering classes... (this may take a moment)\")\n",
        "filtered_indices = []\n",
        "for i in range(len(full_dataset)):\n",
        "    _, label = full_dataset[i]\n",
        "    if label in selected_classes:\n",
        "        filtered_indices.append(i)\n",
        "\n",
        "few_class_dataset = Subset(full_dataset, filtered_indices)\n",
        "\n",
        "label_map = {original: i for i, original in enumerate(selected_classes)}\n",
        "\n",
        "def build_class_index_map(dataset, selected_classes, label_map):\n",
        "    class_indices = {c: [] for c in selected_classes}\n",
        "    for i in range(len(dataset)):\n",
        "        _, label = dataset[i]\n",
        "        class_indices[label].append(i)\n",
        "    return class_indices\n",
        "\n",
        "class_to_indices = build_class_index_map(few_class_dataset, selected_classes, label_map)\n",
        "\n",
        "def create_episode(dataset, class_indices, n_way=3, k_shot=5, q_query=10):\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "\n",
        "    for cls in selected_classes:\n",
        "        indices = class_indices[cls]\n",
        "        sampled = random.sample(indices, k_shot + q_query)\n",
        "        support = sampled[:k_shot]\n",
        "        query = sampled[k_shot:]\n",
        "\n",
        "        support_set.extend([(dataset[s_idx][0], label_map[cls]) for s_idx in support])\n",
        "        query_set.extend([(dataset[q_idx][0], label_map[cls]) for q_idx in query])\n",
        "\n",
        "    return support_set, query_set\n",
        "\n",
        "support, query = create_episode(few_class_dataset, class_to_indices)\n",
        "\n",
        "print(f\"Support set: {len(support)} samples\")\n",
        "print(f\"Query set: {len(query)} samples\")\n",
        "\n",
        "event_tensor, label = support[0]\n",
        "print(f\"Support sample shape: {event_tensor.shape}, label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9N3HI6z-fOz"
      },
      "outputs": [],
      "source": [
        "def frames_to_spike_train(frames):\n",
        "    \"\"\"\n",
        "    Convert (T, H, W, P) event frames to (N, T) binary spike train.\n",
        "    - T: time bins\n",
        "    - H, W: spatial\n",
        "    - P: polarity channels (ON/OFF)\n",
        "    - N = H * W * P\n",
        "    \"\"\"\n",
        "    T, H, W, P = frames.shape\n",
        "    spike_train = frames.reshape(T, H * W * P).T  # → (N, T)\n",
        "    return spike_train.astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbG-IUx2-hRJ",
        "outputId": "109bebd6-db20-4b32-cce4-3f3579f3b297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spike train shape: (2312, 1223)  # (input_neurons, time)\n",
            "Label: 0\n"
          ]
        }
      ],
      "source": [
        "example_frame, label = support[0]\n",
        "spike_train = frames_to_spike_train(example_frame)\n",
        "\n",
        "print(f\"Spike train shape: {spike_train.shape}  # (input_neurons, time)\")\n",
        "print(f\"Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RU8GptQ-jWA"
      },
      "outputs": [],
      "source": [
        "def prepare_set(spike_data):\n",
        "    spike_trains = []\n",
        "    labels = []\n",
        "    for frames, label in spike_data:\n",
        "        train = frames_to_spike_train(frames)\n",
        "        spike_trains.append(train)\n",
        "        labels.append(label)\n",
        "    return spike_trains, labels\n",
        "\n",
        "support_trains, support_labels = prepare_set(support)\n",
        "query_trains, query_labels = prepare_set(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZVgMrL2-rNh"
      },
      "outputs": [],
      "source": [
        "def init_network(input_size, output_size):\n",
        "    weights = np.random.rand(output_size, input_size) * 0.5\n",
        "    for i in range(output_size):\n",
        "        weights[i, i::output_size] += 0.5\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYh4tVhI-slu"
      },
      "outputs": [],
      "source": [
        "def reward_modulated_stdp(weights, pre_spikes, post_spikes, reward, lr=0.01):\n",
        "    \"\"\"\n",
        "    weights: (output_neurons, input_neurons)\n",
        "    pre_spikes: (input_neurons, T)\n",
        "    post_spikes: (output_neurons, T)\n",
        "    reward: +1 (correct) or -1 (wrong)\n",
        "    \"\"\"\n",
        "    T = pre_spikes.shape[1]\n",
        "    for t in range(T):\n",
        "        pre = pre_spikes[:, t]\n",
        "        post = post_spikes[:, t]\n",
        "        for o in range(weights.shape[0]):\n",
        "            if post[o]:\n",
        "                dw = reward * lr * pre\n",
        "                weights[o] += dw\n",
        "                weights[o] = np.clip(weights[o], 0, 1)\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uudRji1B-uYs"
      },
      "outputs": [],
      "source": [
        "def run_snn(spike_train, weights, threshold=5):\n",
        "    \"\"\"\n",
        "    spike_train: (input_neurons, T)\n",
        "    weights: (output_neurons, input_neurons)\n",
        "    Returns: output_spike_train: (output_neurons, T)\n",
        "    \"\"\"\n",
        "    T = spike_train.shape[1]\n",
        "    output_size = weights.shape[0]\n",
        "    output_spikes = np.zeros((output_size, T), dtype=np.uint8)\n",
        "    membrane = np.zeros(output_size)\n",
        "\n",
        "    for t in range(T):\n",
        "        input_t = spike_train[:, t]\n",
        "        membrane += weights @ input_t\n",
        "        fired = membrane >= threshold\n",
        "        output_spikes[:, t] = fired.astype(np.uint8)\n",
        "        membrane[fired] = 0\n",
        "\n",
        "    return output_spikes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmHWBQt4-4l7"
      },
      "outputs": [],
      "source": [
        "def predict(spike_train, weights):\n",
        "    out_spikes = run_snn(spike_train, weights)\n",
        "    spike_counts = out_spikes.sum(axis=1)\n",
        "    return np.argmax(spike_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPy2e2W_-6Yg"
      },
      "outputs": [],
      "source": [
        "def evaluate(query_trains, query_labels, weights):\n",
        "    correct = 0\n",
        "    for spikes, label in zip(query_trains, query_labels):\n",
        "        pred = predict(spikes, weights)\n",
        "        correct += (pred == label)\n",
        "    accuracy = correct / len(query_labels)\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuVdirS3Gd39"
      },
      "outputs": [],
      "source": [
        "def train_on_support(support_trains, support_labels, weights, n_epochs=1):\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch+1}\")\n",
        "        for i, (spikes, label) in enumerate(zip(support_trains, support_labels)):\n",
        "            out_spikes = run_snn(spikes, weights)\n",
        "            predicted = np.argmax(out_spikes.sum(axis=1))\n",
        "            reward = 1 if predicted == label else -1\n",
        "            weights = reward_modulated_stdp(weights, spikes, out_spikes, reward, lr=0.1)\n",
        "\n",
        "            print(f\" Sample {i}: Label={label}, Pred={predicted}, Reward={reward}\")\n",
        "            print(\" Output spikes:\", out_spikes.sum(axis=1))\n",
        "    return weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJCoVw2N-8WP",
        "outputId": "a331ef94-c4ae-480d-a46f-5af6d5266c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [353 351 342]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [454 445 443]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [646 650 641]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [238 243 239]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [106 104 101]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [67 65 62]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [103  99  95]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [87 84 80]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [64 64 61]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [58 58 53]\n",
            " Sample 10: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [90 91 89]\n",
            " Sample 11: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [127 129 128]\n",
            " Sample 12: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [71 72 68]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [23 22 23]\n",
            " Sample 14: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [45 45 43]\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [73 68 66]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [105  95  91]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [221 207 197]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [364 342 321]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [453 435 419]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [159 156 152]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [240 237 232]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [233 227 226]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [125 119 122]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [130 127 129]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [235 234 234]\n",
            " Sample 11: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [258 260 261]\n",
            " Sample 12: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [335 341 342]\n",
            " Sample 13: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [287 298 295]\n",
            " Sample 14: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [345 354 353]\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [355 355 348]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [438 436 427]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [635 627 628]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [627 629 623]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [251 248 250]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [97 96 95]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [156 156 154]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [150 148 150]\n",
            " Sample 8: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [88 89 87]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [149 146 142]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [185 184 184]\n",
            " Sample 11: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [258 255 258]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [116 113 110]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [29 28 28]\n",
            " Sample 14: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [77 77 77]\n",
            "Query set accuracy: 43.33%\n"
          ]
        }
      ],
      "source": [
        "input_neurons = support_trains[0].shape[0]\n",
        "output_neurons = len(set(support_labels))\n",
        "\n",
        "weights = init_network(input_neurons, output_neurons)\n",
        "\n",
        "weights = train_on_support(support_trains, support_labels, weights, n_epochs=3)\n",
        "\n",
        "acc = evaluate(query_trains, query_labels, weights)\n",
        "print(f\"Query set accuracy: {acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkzHgaX-_YR",
        "outputId": "613a9756-0889-4300-901b-93a471daca39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [385 387 388]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [107 105  97]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [148 139 129]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [160 148 141]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [342 317 311]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [275 266 255]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [229 229 208]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [120 116 109]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [140 133 131]\n",
            " Sample 9: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [59 61 60]\n",
            " Sample 10: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [268 273 262]\n",
            " Sample 11: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [125 125 117]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [181 168 172]\n",
            " Sample 13: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [43 44 43]\n",
            " Sample 14: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [72 69 65]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [329 327 329]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [238 232 239]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [355 357 363]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [260 266 260]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [184 188 191]\n",
            " Sample 5: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [79 80 83]\n",
            " Sample 6: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [50 52 53]\n",
            " Sample 7: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [47 48 48]\n",
            " Sample 8: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [59 60 63]\n",
            " Sample 9: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [54 55 55]\n",
            " Sample 10: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [ 96 101  98]\n",
            " Sample 11: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [128 136 127]\n",
            " Sample 12: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [55 56 57]\n",
            " Sample 13: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [94 99 99]\n",
            " Sample 14: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [75 79 81]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [336 334 332]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [470 475 469]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [319 314 318]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [404 406 398]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [283 281 285]\n",
            " Sample 5: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [46 48 49]\n",
            " Sample 6: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [51 54 56]\n",
            " Sample 7: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [56 59 61]\n",
            " Sample 8: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [72 70 73]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [37 37 34]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [58 58 55]\n",
            " Sample 11: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [71 69 67]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [77 75 69]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [105 101 102]\n",
            " Sample 14: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [44 45 43]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [407 410 394]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [148 140 147]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [244 238 236]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [361 355 363]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [230 220 214]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [137 134 131]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [131 127 121]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [92 92 87]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [152 141 139]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [50 46 48]\n",
            " Sample 10: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [95 90 98]\n",
            " Sample 11: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [192 180 188]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [191 175 185]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [52 49 51]\n",
            " Sample 14: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [158 136 141]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [373 376 368]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [113 111 117]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [140 140 145]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [99 99 98]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [138 132 134]\n",
            " Sample 5: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [119 118 129]\n",
            " Sample 6: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [80 77 83]\n",
            " Sample 7: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [90 83 91]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [46 42 46]\n",
            " Sample 9: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [32 31 34]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [103  96  95]\n",
            " Sample 11: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [132 124 124]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [50 47 46]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [40 40 40]\n",
            " Sample 14: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [87 81 86]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [365 379 361]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [165 169 172]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [91 91 93]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [70 72 68]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [99 97 97]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [81 80 77]\n",
            " Sample 6: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [49 51 51]\n",
            " Sample 7: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [72 75 70]\n",
            " Sample 8: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [105 103  99]\n",
            " Sample 9: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [44 45 45]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [150 145 147]\n",
            " Sample 11: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [105 103 107]\n",
            " Sample 12: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [150 151 162]\n",
            " Sample 13: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [304 303 326]\n",
            " Sample 14: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [447 451 464]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [398 385 394]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [613 610 614]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [179 174 179]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [338 321 336]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            " Output spikes: [534 521 532]\n",
            " Sample 5: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [389 384 394]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [245 242 238]\n",
            " Sample 7: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [121 124 126]\n",
            " Sample 8: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [121 125 122]\n",
            " Sample 9: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [ 99 102 102]\n",
            " Sample 10: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [300 295 305]\n",
            " Sample 11: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [411 404 416]\n",
            " Sample 12: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [488 485 494]\n",
            " Sample 13: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [578 568 582]\n",
            " Sample 14: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [510 512 509]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [337 344 341]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [139 140 144]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [114 115 114]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [69 73 71]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [56 57 56]\n",
            " Sample 5: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [30 33 30]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [32 32 28]\n",
            " Sample 7: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [40 42 40]\n",
            " Sample 8: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [25 26 24]\n",
            " Sample 9: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [58 60 54]\n",
            " Sample 10: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [129 141 134]\n",
            " Sample 11: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [63 62 65]\n",
            " Sample 12: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [144 139 140]\n",
            " Sample 13: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [84 87 88]\n",
            " Sample 14: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [134 140 143]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [325 331 325]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [86 89 90]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [185 195 187]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [68 74 70]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [57 59 62]\n",
            " Sample 5: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [58 60 53]\n",
            " Sample 6: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [62 62 66]\n",
            " Sample 7: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [37 38 38]\n",
            " Sample 8: Label=1, Pred=1, Reward=1\n",
            " Output spikes: [40 41 41]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [44 42 40]\n",
            " Sample 10: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [87 87 87]\n",
            " Sample 11: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [85 88 85]\n",
            " Sample 12: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [86 92 91]\n",
            " Sample 13: Label=2, Pred=0, Reward=-1\n",
            " Output spikes: [44 44 44]\n",
            " Sample 14: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [30 32 32]\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [187 194 195]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [317 327 327]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [111 118 112]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            " Output spikes: [84 88 87]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            " Output spikes: [68 70 72]\n",
            " Sample 5: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [28 27 28]\n",
            " Sample 6: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [32 32 32]\n",
            " Sample 7: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [34 33 34]\n",
            " Sample 8: Label=1, Pred=2, Reward=-1\n",
            " Output spikes: [25 26 27]\n",
            " Sample 9: Label=1, Pred=0, Reward=-1\n",
            " Output spikes: [34 33 32]\n",
            " Sample 10: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [62 66 63]\n",
            " Sample 11: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [41 45 40]\n",
            " Sample 12: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [55 57 58]\n",
            " Sample 13: Label=2, Pred=1, Reward=-1\n",
            " Output spikes: [94 95 95]\n",
            " Sample 14: Label=2, Pred=2, Reward=1\n",
            " Output spikes: [70 68 73]\n",
            "Average accuracy over 10 episodes: 32.00%\n",
            "Average spikes per sample: 3910.2\n"
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "\n",
        "for _ in range(10):  # 10 few-shot episodes\n",
        "    class_to_indices = build_class_index_map(few_class_dataset, selected_classes, label_map)\n",
        "    support, query = create_episode(few_class_dataset, class_to_indices, n_way=3, k_shot=5, q_query=5)\n",
        "\n",
        "    support_trains, support_labels = prepare_set(support)\n",
        "    query_trains, query_labels = prepare_set(query)\n",
        "\n",
        "    input_neurons = support_trains[0].shape[0]\n",
        "    output_neurons = len(set(support_labels))\n",
        "\n",
        "    weights = init_network(input_neurons, output_neurons)\n",
        "    weights = train_on_support(support_trains, support_labels, weights)\n",
        "    acc = evaluate(query_trains, query_labels, weights)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "print(f\"Average accuracy over 10 episodes: {np.mean(accuracies)*100:.2f}%\")\n",
        "avg_input_spikes = np.mean([train.sum() for train in support_trains])\n",
        "print(f\"Average spikes per sample: {avg_input_spikes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu9gezlEgXwB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# -----------------------\n",
        "# Network Initialization\n",
        "# -----------------------\n",
        "def init_network(input_size, output_size):\n",
        "    weights = np.random.rand(output_size, input_size) * 0.5\n",
        "    return weights\n",
        "\n",
        "# -----------------------\n",
        "# WTA SNN Inference\n",
        "# -----------------------\n",
        "def run_snn_wta(spike_train, weights, threshold=5):\n",
        "    T = spike_train.shape[1]\n",
        "    output_size = weights.shape[0]\n",
        "    output_spikes = np.zeros((output_size, T), dtype=np.uint8)\n",
        "    membrane = np.zeros(output_size)\n",
        "\n",
        "    for t in range(T):\n",
        "        input_t = spike_train[:, t]\n",
        "        membrane += weights @ input_t\n",
        "        if np.any(membrane >= threshold):\n",
        "            winner = np.argmax(membrane)\n",
        "            output_spikes[winner, t] = 1\n",
        "            membrane[winner] = 0\n",
        "    return output_spikes\n",
        "\n",
        "# -----------------------\n",
        "# Reward-Modulated STDP\n",
        "# -----------------------\n",
        "def reward_modulated_stdp(weights, pre_spikes, post_spikes, reward, lr=0.1):\n",
        "    T = pre_spikes.shape[1]\n",
        "    for t in range(T):\n",
        "        pre = pre_spikes[:, t]\n",
        "        post = post_spikes[:, t]\n",
        "        for o in range(weights.shape[0]):\n",
        "            if post[o]:\n",
        "                dw = reward * lr * pre\n",
        "                weights[o] += dw\n",
        "                weights[o] = np.clip(weights[o], 0, 1)\n",
        "    return weights\n",
        "\n",
        "# -----------------------\n",
        "# Training Loop\n",
        "# -----------------------\n",
        "def train_on_support(support_trains, support_labels, weights, n_epochs=3):\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "        for i, (spikes, label) in enumerate(zip(support_trains, support_labels)):\n",
        "            out_spikes = run_snn_wta(spikes, weights)\n",
        "            predicted = np.argmax(out_spikes.sum(axis=1))\n",
        "            reward = 1 if predicted == label else -1\n",
        "            weights = reward_modulated_stdp(weights, spikes, out_spikes, reward)\n",
        "\n",
        "            print(f\" Sample {i}: Label={label}, Pred={predicted}, Reward={reward}\")\n",
        "            print(\"  Output spikes:\", out_spikes.sum(axis=1))\n",
        "    return weights\n",
        "\n",
        "# -----------------------\n",
        "# Inference\n",
        "# -----------------------\n",
        "def predict(spike_train, weights):\n",
        "    out_spikes = run_snn_wta(spike_train, weights)\n",
        "    spike_counts = out_spikes.sum(axis=1)\n",
        "    return np.argmax(spike_counts)\n",
        "\n",
        "# -----------------------\n",
        "# Evaluation\n",
        "# -----------------------\n",
        "def evaluate(query_trains, query_labels, weights):\n",
        "    correct = 0\n",
        "    for spikes, label in zip(query_trains, query_labels):\n",
        "        pred = predict(spikes, weights)\n",
        "        correct += (pred == label)\n",
        "    accuracy = correct / len(query_labels)\n",
        "    return accuracy\n",
        "\n",
        "# -----------------------\n",
        "# Visualization (Optional)\n",
        "# -----------------------\n",
        "def plot_raster(spike_train, title=\"Output spikes\"):\n",
        "    neuron_ids, times = np.nonzero(spike_train)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.scatter(times, neuron_ids, s=5)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Neuron\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdFRD8sBgdFC",
        "outputId": "714db55d-1db9-4e2f-cd03-c8e663543b87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [132 140 137]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [178 180 171]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [ 97 109  99]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [83 80 84]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [35 34 35]\n",
            " Sample 5: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [72 70 73]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [23 24 23]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [34 33 37]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [40 38 39]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [58 62 61]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [22 22 24]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [15 15 15]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [19 18 20]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [22 21 22]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [17 16 18]\n",
            " Sample 15: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [14 12 15]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [ 9  9 10]\n",
            " Sample 17: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [12 11 13]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [11 11 11]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [ 9  8 10]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [32 32 33]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [72 70 69]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [22 20 26]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [36 35 40]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [90 92 97]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [146 155 161]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [200 207 215]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [238 243 246]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [266 263 268]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [257 255 258]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [236 233 233]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [287 288 288]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [291 296 300]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [257 254 257]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [281 280 283]\n",
            " Sample 5: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [228 231 236]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [94 97 97]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [148 151 154]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [108 111 118]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [ 96 103  95]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [66 72 68]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [70 77 73]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [107 118 114]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [112 129 121]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [162 170 167]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [182 191 183]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [155 165 159]\n",
            " Sample 17: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [208 215 216]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [184 189 186]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [204 207 203]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [236 239 241]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [293 297 295]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [208 217 212]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [192 207 195]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [192 190 189]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [103 107 102]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [100  98  94]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [62 70 69]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [102 103 104]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [103 101 103]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [58 63 61]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [78 78 79]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [60 63 61]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [65 71 68]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [24 25 26]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [30 29 30]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [23 23 23]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [39 39 41]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [55 53 57]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [31 27 31]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [26 27 32]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [19 19 22]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [20 22 24]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [33 31 34]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [23 24 27]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [15 16 16]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [16 17 18]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [20 18 19]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [20 20 24]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [16 14 15]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [45 43 44]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [41 43 41]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [17 20 21]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [27 26 30]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [80 81 87]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [132 127 143]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [200 193 208]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [236 230 247]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [265 261 266]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [255 251 258]\n",
            "Episode accuracy: 40.00%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [214 209 215]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [134 121 124]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [204 191 195]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [260 246 251]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [271 263 263]\n",
            " Sample 5: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [297 296 298]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [276 270 276]\n",
            " Sample 7: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [271 273 273]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [254 254 256]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [212 206 208]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [159 162 162]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [196 191 196]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [80 79 80]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [122 117 119]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [111 106 108]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [111 111 106]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [74 69 71]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [65 64 60]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [53 51 50]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [51 48 49]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [160 153 156]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [144 140 134]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [118 114 118]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [82 74 69]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [97 89 83]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [26 26 27]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [81 82 86]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [115 117 122]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [182 187 183]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [161 152 166]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [240 227 240]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [277 272 277]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [293 285 288]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [299 294 299]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [298 295 295]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [317 317 317]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [317 316 316]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [292 293 294]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [277 277 277]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [286 288 288]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [206 199 206]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [177 181 186]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [72 72 72]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [105 101 105]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [94 93 98]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [125 122 124]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [62 62 61]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [71 68 69]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [41 43 40]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [58 60 58]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [208 208 212]\n",
            " Sample 21: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [268 263 270]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [255 251 256]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [285 287 285]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [271 273 272]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [177 176 176]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [227 227 230]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [240 245 241]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [219 224 217]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [241 237 235]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [197 205 200]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [174 176 178]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [70 71 71]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [36 39 41]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [74 68 73]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [93 94 93]\n",
            " Sample 6: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [89 86 92]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [47 43 49]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [54 47 53]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [70 58 67]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [54 45 58]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [40 32 42]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [17 14 17]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [21 17 23]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [26 23 27]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [28 23 24]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [22 18 21]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [19 15 18]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [13 12 15]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [15 13 15]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [77 66 73]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [70 61 67]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [55 45 50]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [42 31 37]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [52 41 45]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [11 10 12]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [44 35 39]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [25 22 22]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [21 16 19]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [46 38 42]\n",
            "Episode accuracy: 33.33%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [219 218 219]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [254 253 252]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [252 256 253]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [278 275 277]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [305 301 302]\n",
            " Sample 5: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [286 288 289]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [275 274 275]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [286 283 285]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [282 277 283]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [251 254 254]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [156 155 154]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [131 127 130]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [152 148 151]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [132 130 125]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [65 66 64]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [73 78 70]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [93 95 88]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [163 163 159]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [86 88 82]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 97 100  91]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [208 219 203]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [205 209 203]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [106  98 107]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [185 176 187]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [205 204 213]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [251 247 257]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [255 252 258]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [267 260 268]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [248 244 249]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [270 271 272]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [295 293 295]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [296 295 295]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [293 290 290]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [315 314 316]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [310 308 310]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [292 293 293]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [282 282 282]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [298 296 297]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [287 284 283]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [276 277 276]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [202 199 201]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [191 190 194]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [211 208 215]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [198 191 198]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [103  98 104]\n",
            " Sample 15: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [85 85 89]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [66 63 68]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [121 119 121]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [52 51 56]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [34 33 36]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [174 175 175]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [183 185 183]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [115 114 116]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [202 202 206]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [211 215 219]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [255 255 260]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [258 256 259]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [268 267 269]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [252 252 251]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [259 257 256]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [286 286 287]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [261 262 267]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [158 159 166]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [230 227 232]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [138 135 135]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [215 208 209]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [258 245 251]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [277 272 277]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [277 273 276]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [269 269 269]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [205 202 203]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [195 194 195]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [216 213 219]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [209 205 207]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [115 113 116]\n",
            " Sample 15: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [93 94 97]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [71 71 73]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [130 132 130]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [115 114 117]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [64 63 60]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [199 200 196]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [199 196 198]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [138 133 136]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [198 194 192]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [134 136 136]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [129 136 132]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [71 70 70]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [72 73 69]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [41 46 43]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [23 24 23]\n",
            "Episode accuracy: 53.33%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [210 209 213]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [129 125 124]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [214 212 209]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [245 247 242]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [215 212 219]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [137 131 128]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [232 225 231]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [272 270 278]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [192 182 188]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [247 242 247]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [193 185 194]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [185 176 185]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 98 101  99]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [108 112 112]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [173 174 171]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [165 165 161]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [189 189 192]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [146 154 150]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [132 133 133]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [227 228 229]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [200 199 199]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [229 224 222]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [151 154 149]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [86 90 90]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [85 86 82]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [78 77 74]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [58 57 57]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [53 53 55]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [86 87 89]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [161 160 166]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [231 235 242]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [177 176 185]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [107 100 103]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [160 154 155]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [236 225 233]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [274 267 266]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [286 287 280]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [275 264 265]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [295 287 289]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [288 285 286]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [236 231 232]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [215 215 219]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [158 157 159]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [115 116 115]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [187 187 182]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [127 126 124]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [141 139 145]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [108 105 108]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [96 91 96]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [135 134 135]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [146 143 142]\n",
            " Sample 21: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [210 208 211]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [236 241 235]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [172 176 176]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [151 149 146]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [124 118 128]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [200 197 197]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [142 138 151]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [196 187 204]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [245 245 253]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [277 275 280]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [254 250 262]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [212 203 213]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [114 111 116]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [88 84 89]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [63 64 62]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [95 93 92]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [170 174 175]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [48 52 53]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [87 77 82]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [60 51 57]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [65 58 63]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [26 23 25]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [24 22 24]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [25 25 25]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [22 21 22]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [21 21 18]\n",
            " Sample 17: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [17 17 18]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [19 21 22]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [25 25 25]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [40 41 40]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [87 79 87]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [32 31 33]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [63 58 59]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [53 54 49]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [62 63 58]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [34 35 30]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [33 33 39]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [59 56 61]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [111 107 126]\n",
            "Episode accuracy: 33.33%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [197 201 197]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [137 147 136]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [68 71 71]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [43 44 42]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [46 47 42]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [29 31 27]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [32 36 35]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [43 43 45]\n",
            " Sample 8: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [32 36 36]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [19 19 18]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [27 26 23]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [18 17 15]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [10 10  9]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [11 11  9]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [11 11 11]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [13 11 12]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [14 13 14]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [18 19 18]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [21 21 21]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [14 12 14]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [23 27 27]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [40 41 41]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [17 18 17]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [30 33 34]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [46 47 51]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [91 89 99]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [137 137 140]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [180 183 187]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [85 85 84]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [226 224 224]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [167 166 163]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [246 239 243]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [258 257 257]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [306 300 300]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [303 304 304]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [284 282 279]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [291 287 285]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [309 307 307]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [316 315 315]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [305 306 306]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [233 234 234]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [227 226 227]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [149 150 158]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [140 137 139]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [136 138 143]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [168 173 171]\n",
            " Sample 16: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [220 220 224]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [223 222 219]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [136 139 143]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [81 83 86]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [210 212 221]\n",
            " Sample 21: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [228 227 234]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [277 272 279]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [283 281 286]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [279 275 278]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [265 263 264]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [251 246 248]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [210 204 204]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [56 53 58]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [186 166 179]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [186 180 189]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [199 186 197]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [214 197 216]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [195 175 191]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [259 240 245]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [282 272 274]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [288 281 287]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [306 304 308]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [292 288 289]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [295 290 293]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [250 251 251]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [238 233 233]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [162 162 160]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [151 151 148]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [152 153 150]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [205 203 205]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [207 200 204]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [215 213 211]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [115 113 112]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [78 74 81]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [237 238 240]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [240 238 240]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [231 220 232]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [265 258 264]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [225 220 229]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [254 246 253]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [231 225 233]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [263 253 262]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [87 86 86]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [237 226 231]\n",
            "Episode accuracy: 66.67%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [212 210 211]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [247 244 241]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [271 272 268]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [260 261 261]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [210 219 205]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [91 90 91]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [182 181 175]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [235 235 229]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [279 278 275]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [298 300 295]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [169 168 173]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [152 158 152]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [137 140 140]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [167 174 179]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [109 115 112]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [173 181 179]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [200 205 203]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [214 220 219]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [205 208 206]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [224 223 217]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [217 215 212]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [260 252 255]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [223 227 219]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [147 142 151]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [167 167 172]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [219 208 221]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [259 260 262]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [217 216 222]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [295 293 297]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [275 277 277]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [279 279 280]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [249 252 252]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [234 233 238]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [170 157 170]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [263 247 264]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [161 147 160]\n",
            " Sample 6: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [230 223 232]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [148 133 149]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [132 129 133]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [81 79 79]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [94 90 88]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [78 73 73]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [50 50 49]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [42 40 43]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [30 27 26]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [41 37 38]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [32 32 31]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [30 27 29]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [18 17 15]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [36 33 33]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [34 39 39]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [54 49 49]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [62 65 61]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [41 39 41]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [20 19 21]\n",
            " Sample 25: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [31 26 33]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [54 52 63]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [68 61 74]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [183 175 195]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [183 178 199]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [237 234 249]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [182 174 193]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [159 146 167]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [106  99  99]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [184 176 177]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [243 225 224]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [265 255 253]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [286 279 278]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [304 299 301]\n",
            " Sample 9: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [311 310 314]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [213 208 212]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [203 206 204]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [185 178 178]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [183 176 177]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [115 109 111]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [159 155 157]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [124 120 122]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [96 97 95]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [91 95 95]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [154 149 153]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [168 169 170]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [249 256 256]\n",
            " Sample 22: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [211 214 217]\n",
            " Sample 23: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [233 230 241]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [229 231 230]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [230 221 226]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [224 219 220]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [101  98  99]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [251 247 243]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [65 64 65]\n",
            "Episode accuracy: 40.00%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [220 217 221]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [129 122 130]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [68 67 70]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [53 50 51]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [105 108 116]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [46 51 49]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [26 30 29]\n",
            " Sample 7: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [32 33 31]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [41 41 40]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [75 81 80]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [16 21 21]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [29 39 41]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [26 34 33]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [29 36 33]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [38 47 46]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [60 78 74]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 94 113 108]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [100 129 123]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [129 158 152]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [144 169 167]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [212 236 239]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [238 252 252]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [127 137 131]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [171 194 186]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [168 194 180]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [77 86 77]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [102 105 100]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [46 46 43]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [46 47 47]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [24 23 22]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [46 48 44]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [44 48 43]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [26 28 24]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [26 27 24]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [28 29 23]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [14 12 12]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [17 19 15]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [19 19 17]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [50 49 42]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [103  95  75]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [52 59 41]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [111 116  83]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [158 163 112]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [141 146 102]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [169 173 124]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [199 199 156]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [154 155 117]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [202 208 155]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [206 210 171]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [203 206 174]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [259 263 236]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [223 228 198]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [104 103  87]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [157 156 132]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [140 143 118]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [53 57 53]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [95 91 80]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [29 30 30]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [35 40 37]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [17 19 16]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [52 53 45]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [43 43 39]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [78 81 71]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [48 50 45]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [30 27 31]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [28 25 26]\n",
            " Sample 6: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [30 28 31]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [41 37 41]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [98 87 92]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [178 160 164]\n",
            " Sample 10: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [85 76 89]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [127 119 134]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [89 83 95]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [55 45 61]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [49 40 48]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [78 70 74]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [53 45 44]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [38 31 37]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [27 23 26]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [19 16 20]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [94 86 86]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [57 49 50]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [37 35 33]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [78 69 63]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [50 44 46]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [44 46 43]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [64 59 58]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [25 22 22]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [25 24 23]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [14 14 14]\n",
            "Episode accuracy: 33.33%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [194 195 192]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [111 115 110]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [56 63 59]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [81 88 81]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [67 68 70]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [37 39 35]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [17 17 17]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [44 44 45]\n",
            " Sample 8: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [35 38 36]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [19 20 19]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [15 16 16]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [15 17 16]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [27 34 29]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [26 33 31]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [38 51 47]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [27 36 33]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [65 91 82]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 76 106  92]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [51 72 64]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [112 155 138]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [163 214 191]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [126 156 146]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [100 127 117]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [ 73 102  90]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [67 73 69]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [30 36 34]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [31 35 33]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [20 19 20]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [28 29 28]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [20 23 21]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [18 20 18]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [12 15 13]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [10 13 11]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [23 29 24]\n",
            " Sample 4: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [16 18 19]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [12 15 13]\n",
            " Sample 6: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [7 7 9]\n",
            " Sample 7: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [13 14 14]\n",
            " Sample 8: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [15 17 17]\n",
            " Sample 9: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [8 8 9]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [6 7 6]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [5 8 6]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 9 13 10]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 9 14 10]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [13 21 15]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 9 16 12]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [23 37 29]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [28 49 36]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [20 33 26]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [49 83 60]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [ 74 126  98]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [55 81 66]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [44 62 53]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [34 52 43]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [35 42 36]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [17 24 19]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [18 24 20]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [12 14 14]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [16 20 19]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [11 18 14]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [13 13 13]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [19 20 20]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [14 16 13]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [23 28 24]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [15 18 16]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [13 15 13]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [8 8 8]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [20 19 18]\n",
            " Sample 8: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [40 46 36]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [18 23 18]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 9 12  9]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 9 12  9]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [19 24 16]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [17 24 17]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [28 35 25]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [20 26 19]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [54 64 47]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [61 77 56]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [43 52 40]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [101 124  93]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [147 176 129]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [ 97 118  93]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [81 93 74]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [64 76 61]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [46 52 45]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 26 23]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [26 28 25]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [16 14 14]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 25 20]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [19 18 16]\n",
            "Episode accuracy: 40.00%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [222 226 224]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [107 113 108]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [60 58 57]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [73 73 74]\n",
            " Sample 4: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [102 108 103]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [49 53 52]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [43 46 44]\n",
            " Sample 7: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [35 37 38]\n",
            " Sample 8: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [29 29 30]\n",
            " Sample 9: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [24 28 29]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [16 20 20]\n",
            " Sample 11: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [23 29 30]\n",
            " Sample 12: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [14 19 21]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [12 16 17]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [11 13 13]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [19 25 22]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [26 33 29]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [35 49 40]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [46 60 52]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [57 74 62]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [109 140 121]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [100 117 104]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [45 53 48]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [42 48 45]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 28 25]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 25 23]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 28 24]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [24 27 26]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [21 21 24]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [32 31 27]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [28 30 28]\n",
            " Sample 1: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [18 17 19]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [13 15 15]\n",
            " Sample 3: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [ 9  9 10]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [23 23 23]\n",
            " Sample 5: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [38 40 39]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [24 26 26]\n",
            " Sample 7: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [24 27 25]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [18 17 18]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [30 35 32]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [13 16 12]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [19 21 17]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [25 26 22]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [32 36 30]\n",
            " Sample 14: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [43 47 41]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [61 73 66]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [ 90 102  85]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [111 120 114]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [122 139 124]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [132 146 129]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [210 222 207]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [171 186 178]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [105 121 112]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [73 78 73]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [57 65 54]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [44 50 40]\n",
            " Sample 26: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [44 47 37]\n",
            " Sample 27: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [26 29 26]\n",
            " Sample 28: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [32 33 31]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [18 20 14]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [24 24 20]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [45 45 34]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [87 88 61]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [37 34 29]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [101  93  78]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [175 171 142]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [244 241 213]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [264 263 244]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [291 287 277]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [274 271 266]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [251 246 241]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [211 208 202]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [171 163 160]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [174 169 168]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [98 90 93]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [175 168 167]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [95 87 87]\n",
            " Sample 17: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [117 119 118]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [80 81 75]\n",
            " Sample 19: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [90 94 90]\n",
            " Sample 20: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [250 245 243]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [247 245 237]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [143 144 143]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [151 149 149]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [88 90 91]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [135 135 129]\n",
            " Sample 26: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [64 64 73]\n",
            " Sample 27: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [173 170 180]\n",
            " Sample 28: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [226 223 235]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [241 234 242]\n",
            "Episode accuracy: 26.67%\n",
            "\n",
            "Epoch 1\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [212 217 216]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [109 122 121]\n",
            " Sample 2: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [87 87 89]\n",
            " Sample 3: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [69 70 64]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [44 40 41]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [88 81 80]\n",
            " Sample 6: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [126 130 120]\n",
            " Sample 7: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [85 86 83]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [65 64 60]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [121 121 111]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [104 106 101]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [148 151 142]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [177 179 174]\n",
            " Sample 13: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [165 167 164]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [194 192 193]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [195 200 200]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [192 200 188]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [179 179 173]\n",
            " Sample 18: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [216 214 213]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [147 146 146]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [210 212 209]\n",
            " Sample 21: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [149 142 143]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [107 103 104]\n",
            " Sample 23: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [91 93 91]\n",
            " Sample 24: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [62 58 57]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [32 31 28]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [42 38 42]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [48 48 44]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [34 33 33]\n",
            " Sample 29: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [14 14 14]\n",
            "\n",
            "Epoch 2\n",
            " Sample 0: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [37 43 39]\n",
            " Sample 1: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [37 37 33]\n",
            " Sample 2: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [81 75 66]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [141 134 108]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [190 180 150]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [257 244 224]\n",
            " Sample 6: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [276 270 250]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [295 290 283]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [304 300 293]\n",
            " Sample 9: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [296 295 295]\n",
            " Sample 10: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [210 208 208]\n",
            " Sample 11: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [235 233 234]\n",
            " Sample 12: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [218 217 218]\n",
            " Sample 13: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [152 149 150]\n",
            " Sample 14: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [171 170 168]\n",
            " Sample 15: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [190 191 188]\n",
            " Sample 16: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [208 209 207]\n",
            " Sample 17: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [141 149 151]\n",
            " Sample 18: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [193 196 200]\n",
            " Sample 19: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [103 107 117]\n",
            " Sample 20: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [221 223 225]\n",
            " Sample 21: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [262 257 263]\n",
            " Sample 22: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [270 271 271]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [252 248 249]\n",
            " Sample 24: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [206 206 208]\n",
            " Sample 25: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [251 248 244]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [250 241 243]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [222 222 219]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [154 154 150]\n",
            " Sample 29: Label=2, Pred=2, Reward=1\n",
            "  Output spikes: [68 73 74]\n",
            "\n",
            "Epoch 3\n",
            " Sample 0: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [197 197 196]\n",
            " Sample 1: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [247 251 246]\n",
            " Sample 2: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [219 221 213]\n",
            " Sample 3: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [132 122 125]\n",
            " Sample 4: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [177 173 174]\n",
            " Sample 5: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [250 246 244]\n",
            " Sample 6: Label=0, Pred=2, Reward=-1\n",
            "  Output spikes: [266 266 270]\n",
            " Sample 7: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [256 253 252]\n",
            " Sample 8: Label=0, Pred=0, Reward=1\n",
            "  Output spikes: [289 288 285]\n",
            " Sample 9: Label=0, Pred=1, Reward=-1\n",
            "  Output spikes: [285 288 286]\n",
            " Sample 10: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [145 146 145]\n",
            " Sample 11: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [195 202 194]\n",
            " Sample 12: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [222 226 225]\n",
            " Sample 13: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [200 196 202]\n",
            " Sample 14: Label=1, Pred=2, Reward=-1\n",
            "  Output spikes: [202 203 205]\n",
            " Sample 15: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [228 220 226]\n",
            " Sample 16: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [179 172 175]\n",
            " Sample 17: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [69 66 67]\n",
            " Sample 18: Label=1, Pred=1, Reward=1\n",
            "  Output spikes: [115 122 120]\n",
            " Sample 19: Label=1, Pred=0, Reward=-1\n",
            "  Output spikes: [118 118 116]\n",
            " Sample 20: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [215 216 216]\n",
            " Sample 21: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [176 179 178]\n",
            " Sample 22: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [131 130 127]\n",
            " Sample 23: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [129 125 127]\n",
            " Sample 24: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [80 88 76]\n",
            " Sample 25: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [60 61 52]\n",
            " Sample 26: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [74 73 74]\n",
            " Sample 27: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [80 78 78]\n",
            " Sample 28: Label=2, Pred=0, Reward=-1\n",
            "  Output spikes: [53 50 51]\n",
            " Sample 29: Label=2, Pred=1, Reward=-1\n",
            "  Output spikes: [23 24 21]\n",
            "Episode accuracy: 46.67%\n",
            "\n",
            "✅ Average accuracy over 10 episodes: 41.33%\n"
          ]
        }
      ],
      "source": [
        "accuracies = []\n",
        "\n",
        "for _ in range(10):\n",
        "    class_to_indices = build_class_index_map(few_class_dataset, selected_classes, label_map)\n",
        "    support, query = create_episode(few_class_dataset, class_to_indices, n_way=3, k_shot=10, q_query=5)\n",
        "\n",
        "    support_trains, support_labels = prepare_set(support)\n",
        "    query_trains, query_labels = prepare_set(query)\n",
        "\n",
        "    input_neurons = support_trains[0].shape[0]\n",
        "    output_neurons = len(set(support_labels))\n",
        "\n",
        "    weights = init_network(input_neurons, output_neurons)\n",
        "    weights = train_on_support(support_trains, support_labels, weights, n_epochs=3)\n",
        "\n",
        "    acc = evaluate(query_trains, query_labels, weights)\n",
        "    print(f\"Episode accuracy: {acc*100:.2f}%\")\n",
        "    accuracies.append(acc)\n",
        "\n",
        "print(f\"\\n✅ Average accuracy over 10 episodes: {np.mean(accuracies)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhrqPO4cT09G",
        "outputId": "65e7d180-93cc-4526-b8b3-af2767aeb722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Meta-Learning (Prototypical Networks) Simulation...\n",
            "\n",
            "Configuration: 5-way, 5-shot classification.\n",
            "Feature Dimension: 10\n",
            "\n",
            "--- Running Task 1/5 ---\n",
            "  Selected Digits for this Task: [0, 2, 3, 4, 7]\n",
            "  Support Set Size: 25 examples (5 per class)\n",
            "  Query Set Size: 75 examples (15 per class)\n",
            "  Task Accuracy: 100.00%\n",
            "\n",
            "--- Running Task 2/5 ---\n",
            "  Selected Digits for this Task: [0, 1, 5, 6, 7]\n",
            "  Support Set Size: 25 examples (5 per class)\n",
            "  Query Set Size: 75 examples (15 per class)\n",
            "  Task Accuracy: 100.00%\n",
            "\n",
            "--- Running Task 3/5 ---\n",
            "  Selected Digits for this Task: [1, 3, 4, 7, 9]\n",
            "  Support Set Size: 25 examples (5 per class)\n",
            "  Query Set Size: 75 examples (15 per class)\n",
            "  Task Accuracy: 100.00%\n",
            "\n",
            "--- Running Task 4/5 ---\n",
            "  Selected Digits for this Task: [4, 5, 7, 8, 9]\n",
            "  Support Set Size: 25 examples (5 per class)\n",
            "  Query Set Size: 75 examples (15 per class)\n",
            "  Task Accuracy: 100.00%\n",
            "\n",
            "--- Running Task 5/5 ---\n",
            "  Selected Digits for this Task: [3, 6, 7, 8, 9]\n",
            "  Support Set Size: 25 examples (5 per class)\n",
            "  Query Set Size: 75 examples (15 per class)\n",
            "  Task Accuracy: 100.00%\n",
            "\n",
            "--- Simulation Complete ---\n",
            "Average Accuracy across 5 Tasks: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Configuration for the simulation ---\n",
        "NUM_CLASSES_PER_TASK = 5  # How many different digit classes in one task (N-way classification)\n",
        "N_SHOT = 5                # Number of support examples per class (K-shot learning, e.g., 1-shot, 5-shot)\n",
        "N_QUERY = 15              # Number of query examples per class\n",
        "FEATURE_DIMENSION = 10    # Dimension of our simulated feature vectors (embeddings)\n",
        "NUM_TASKS_TO_SIMULATE = 5 # How many meta-learning tasks to run\n",
        "\n",
        "\n",
        "# --- Simulated MNIST Data Generation ---\n",
        "# In a real scenario, this would come from a pre-trained feature extractor (e.g., a CNN)\n",
        "# Here, we simulate features based on class (digit) to make them distinguishable.\n",
        "def generate_features(digit_class: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generates a simulated feature vector for a given digit class.\n",
        "    Features for the same class will be clustered, but with some noise.\n",
        "    \"\"\"\n",
        "    # Create a base feature vector somewhat unique to the digit class\n",
        "    base_features = np.array([\n",
        "        (digit_class * 0.5 + np.random.uniform(-0.1, 0.1)) for _ in range(FEATURE_DIMENSION)\n",
        "    ])\n",
        "\n",
        "    # Add more noise to simulate variability within a class\n",
        "    features = base_features + np.random.uniform(-0.5, 0.5, size=FEATURE_DIMENSION) * 0.5\n",
        "    return features\n",
        "\n",
        "\n",
        "# --- Task Generation Logic ---\n",
        "def generate_meta_learning_task():\n",
        "    \"\"\"\n",
        "    Generates a single meta-learning task (episode) for few-shot classification.\n",
        "    A task consists of a support set and a query set for randomly selected classes.\n",
        "    \"\"\"\n",
        "    # Randomly select NUM_CLASSES_PER_TASK unique digits for this task\n",
        "    available_digits = list(range(10))  # Digits 0-9\n",
        "    np.random.shuffle(available_digits)\n",
        "    selected_digits = sorted(available_digits[:NUM_CLASSES_PER_TASK])\n",
        "\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "\n",
        "    for digit in selected_digits:\n",
        "        # Generate N_SHOT support examples for this digit\n",
        "        for _ in range(N_SHOT):\n",
        "            support_set.append({\n",
        "                'class': digit,\n",
        "                'features': generate_features(digit)\n",
        "            })\n",
        "        # Generate N_QUERY query examples for this digit\n",
        "        for _ in range(N_QUERY):\n",
        "            query_set.append({\n",
        "                'class': digit,\n",
        "                'features': generate_features(digit)\n",
        "            })\n",
        "\n",
        "    # Shuffle query set to mix classes and avoid sequential bias\n",
        "    np.random.shuffle(query_set)\n",
        "\n",
        "    return {\n",
        "        'selected_digits': selected_digits,\n",
        "        'support_set': support_set,\n",
        "        'query_set': query_set,\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Core Meta-Learning Logic (Prototypical Networks) ---\n",
        "def run_prototypical_network(task: dict) -> tuple[list, float]:\n",
        "    \"\"\"\n",
        "    Implements the Prototypical Network algorithm for a given task.\n",
        "    1. Computes prototypes from the support set.\n",
        "    2. Classifies query examples based on distance to prototypes.\n",
        "    \"\"\"\n",
        "    support_set = task['support_set']\n",
        "    query_set = task['query_set']\n",
        "    class_prototypes = {}  # Stores the prototype (mean embedding) for each class\n",
        "\n",
        "    # 1. Compute Prototypes from Support Set\n",
        "    # Group support examples by class\n",
        "    grouped_support = defaultdict(list)\n",
        "    for item in support_set:\n",
        "        grouped_support[item['class']].append(item['features'])\n",
        "\n",
        "    # Calculate the mean feature vector (prototype) for each class\n",
        "    for class_name, features_for_class in grouped_support.items():\n",
        "        prototype = np.mean(features_for_class, axis=0)\n",
        "        class_prototypes[class_name] = prototype\n",
        "\n",
        "    # 2. Classify Query Set Examples\n",
        "    predictions = []\n",
        "    correct_count = 0\n",
        "\n",
        "    for query_item in query_set:\n",
        "        min_distance = float('inf')\n",
        "        predicted_class = None\n",
        "\n",
        "        # Iterate through each prototype\n",
        "        for class_name, prototype in class_prototypes.items():\n",
        "            # Calculate Euclidean distance between query item's features and prototype\n",
        "            distance = np.linalg.norm(query_item['features'] - prototype)\n",
        "\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                predicted_class = class_name\n",
        "\n",
        "        predictions.append({\n",
        "            'true_class': query_item['class'],\n",
        "            'predicted_class': predicted_class,\n",
        "            'is_correct': (predicted_class == query_item['class'])\n",
        "        })\n",
        "\n",
        "        if predicted_class == query_item['class']:\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = (correct_count / len(query_set)) * 100 if len(query_set) > 0 else 0\n",
        "    return predictions, accuracy\n",
        "\n",
        "\n",
        "# --- Main simulation loop ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Meta-Learning (Prototypical Networks) Simulation...\\n\")\n",
        "    print(f\"Configuration: {NUM_CLASSES_PER_TASK}-way, {N_SHOT}-shot classification.\")\n",
        "    print(f\"Feature Dimension: {FEATURE_DIMENSION}\\n\")\n",
        "\n",
        "    all_accuracies = []\n",
        "\n",
        "    for i in range(1, NUM_TASKS_TO_SIMULATE + 1):\n",
        "        print(f\"--- Running Task {i}/{NUM_TASKS_TO_SIMULATE} ---\")\n",
        "        task = generate_meta_learning_task()\n",
        "\n",
        "        print(f\"  Selected Digits for this Task: {task['selected_digits']}\")\n",
        "        print(f\"  Support Set Size: {len(task['support_set'])} examples ({N_SHOT} per class)\")\n",
        "        print(f\"  Query Set Size: {len(task['query_set'])} examples ({N_QUERY} per class)\")\n",
        "\n",
        "        predictions, accuracy = run_prototypical_network(task)\n",
        "        all_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"  Task Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "        # Optionally print a few predictions to see how it performs\n",
        "        # for j in range(min(5, len(predictions))):\n",
        "        #     p = predictions[j]\n",
        "        #     print(f\"    Query {j+1}: True Class = {p['true_class']}, Predicted = {p['predicted_class']} ({'Correct' if p['is_correct'] else 'Incorrect'})\")\n",
        "        # if len(predictions) > 5:\n",
        "        #     print(\"    ...\")\n",
        "        # print(\"\")\n",
        "\n",
        "    avg_accuracy = np.mean(all_accuracies) if all_accuracies else 0\n",
        "    print(f\"--- Simulation Complete ---\")\n",
        "    print(f\"Average Accuracy across {NUM_TASKS_TO_SIMULATE} Tasks: {avg_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGkNBlYvUOOG",
        "outputId": "e884bee8-3a22-4e9a-f2b1-c7e5feef3102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading snntorch-0.9.4-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: snntorch\n",
            "Successfully installed snntorch-0.9.4\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTO-rqUMUK2m",
        "outputId": "23a4b1bf-534d-49b6-89df-bb2511c17d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 342kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.74MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.28MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n",
            "\n",
            "--- Starting Meta-Training ---\n",
            "Task 100/1000 | Loss: 0.2064 | Accuracy: 93.12%\n",
            "Task 200/1000 | Loss: 0.1507 | Accuracy: 95.01%\n",
            "Task 300/1000 | Loss: 0.1238 | Accuracy: 95.93%\n",
            "Task 400/1000 | Loss: 0.1097 | Accuracy: 96.35%\n",
            "Task 500/1000 | Loss: 0.0989 | Accuracy: 96.72%\n",
            "Task 600/1000 | Loss: 0.0911 | Accuracy: 96.96%\n",
            "Task 700/1000 | Loss: 0.0842 | Accuracy: 97.19%\n",
            "Task 800/1000 | Loss: 0.0795 | Accuracy: 97.36%\n",
            "Task 900/1000 | Loss: 0.0757 | Accuracy: 97.48%\n",
            "Task 1000/1000 | Loss: 0.0720 | Accuracy: 97.61%\n",
            "\n",
            "Meta-Training Complete. Avg Loss: 0.0720 | Avg Accuracy: 97.61%\n",
            "\n",
            "--- Starting Meta-Testing ---\n",
            "Test Task 10/50 | Accuracy: 99.33%\n",
            "Test Task 20/50 | Accuracy: 99.00%\n",
            "Test Task 30/50 | Accuracy: 98.93%\n",
            "Test Task 40/50 | Accuracy: 98.67%\n",
            "Test Task 50/50 | Accuracy: 98.75%\n",
            "\n",
            "Meta-Testing Complete. Avg Accuracy: 98.75%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import utils\n",
        "from snntorch import functional as SF\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- 1. Configuration and Hyperparameters ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# SNN parameters\n",
        "BETA = 0.95  # decay rate for Leaky Integrate-and-Fire neurons\n",
        "SPIKE_GRAD_BETA = 5     # Beta for surrogate gradient (controls slope)\n",
        "NUM_STEPS = 50          # Number of time steps for SNN simulation\n",
        "\n",
        "# Meta-learning parameters\n",
        "NUM_CLASSES_PER_TASK = 5  # N-way classification\n",
        "N_SHOT = 5                # K-shot learning\n",
        "N_QUERY = 15              # Number of query examples per class\n",
        "NUM_META_TRAIN_TASKS = 1000 # Number of meta-training episodes\n",
        "NUM_META_TEST_TASKS = 50    # Number of meta-testing episodes\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Data parameters\n",
        "IMG_SIZE = 28\n",
        "NUM_CHANNELS = 1\n",
        "\n",
        "# --- 2. Data Loading and Task Generation ---\n",
        "\n",
        "class MNISTFewShotDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom dataset class to facilitate few-shot task generation from MNIST.\n",
        "    This stores the entire MNIST dataset and allows sampling of tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        self.mnist = datasets.MNIST(root=root, train=train, download=True, transform=transform)\n",
        "        self.labels_to_indices = self._group_data_by_label()\n",
        "\n",
        "    def _group_data_by_label(self):\n",
        "        \"\"\"Groups indices of samples by their class label.\"\"\"\n",
        "        labels_to_indices = {i: [] for i in range(10)}\n",
        "        for i, (_, label) in enumerate(self.mnist):\n",
        "            labels_to_indices[label].append(i)\n",
        "        return labels_to_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pass\n",
        "\n",
        "    def get_task_batch(self, num_classes_per_task, n_shot, n_query, num_tasks_in_batch):\n",
        "        \"\"\"\n",
        "        Generates a batch of few-shot tasks.\n",
        "        Each task contains a support set and a query set.\n",
        "        \"\"\"\n",
        "        task_batch = []\n",
        "        for _ in range(num_tasks_in_batch):\n",
        "            selected_classes = random.sample(range(10), num_classes_per_task)\n",
        "\n",
        "            support_images, support_labels = [], []\n",
        "            query_images, query_labels = [], []\n",
        "\n",
        "            for class_label in selected_classes:\n",
        "                available_indices = self.labels_to_indices[class_label]\n",
        "                random.shuffle(available_indices)\n",
        "\n",
        "                support_indices = available_indices[:n_shot]\n",
        "                for idx in support_indices:\n",
        "                    image, _ = self.mnist[idx]\n",
        "                    support_images.append(image)\n",
        "                    support_labels.append(class_label)\n",
        "\n",
        "                query_indices = available_indices[n_shot : n_shot + n_query]\n",
        "                for idx in query_indices:\n",
        "                    image, _ = self.mnist[idx]\n",
        "                    query_images.append(image)\n",
        "                    query_labels.append(class_label)\n",
        "\n",
        "            support_images = torch.stack(support_images).to(device)\n",
        "            support_labels = torch.tensor(support_labels).long().to(device)\n",
        "            query_images = torch.stack(query_images).to(device)\n",
        "            query_labels = torch.tensor(query_labels).long().to(device)\n",
        "\n",
        "            task_batch.append({\n",
        "                'selected_classes': selected_classes,\n",
        "                'support_set': (support_images, support_labels),\n",
        "                'query_set': (query_images, query_labels)\n",
        "            })\n",
        "        return task_batch\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = MNISTFewShotDataset(root='./data', train=True, transform=transform)\n",
        "test_dataset = MNISTFewShotDataset(root='./data', train=False, transform=transform)\n",
        "\n",
        "# --- 3. SNN Feature Extractor Model ---\n",
        "\n",
        "class SNNFeatureExtractor(nn.Module):\n",
        "    def __init__(self, beta, spike_grad_beta, num_steps):\n",
        "        super(SNNFeatureExtractor, self).__init__()\n",
        "\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "        self.conv1 = nn.Conv2d(NUM_CHANNELS, 16, kernel_size=5, stride=1, padding=2)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=spike_grad_beta))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=spike_grad_beta))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Input size calculation: 28x28 -> (28/2)x(28/2) = 14x14 after pool1\n",
        "        # 14x14 -> (14/2)x(14/2) = 7x7 after pool2\n",
        "        # So, 32 channels * 7 * 7 = 1568 features\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 64)\n",
        "        self.lif3 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=spike_grad_beta))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        accumulated_features = 0\n",
        "\n",
        "        for step in range(self.num_steps):\n",
        "            # Rate coding: input current proportional to pixel intensity\n",
        "            cur1 = self.conv1(x)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            p1 = self.pool1(spk1)\n",
        "\n",
        "            cur2 = self.conv2(p1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            p2 = self.pool2(spk2)\n",
        "\n",
        "            p2_flat = p2.view(p2.size(0), -1)\n",
        "\n",
        "            cur3 = self.fc1(p2_flat)\n",
        "            spk3, mem3 = self.lif3(cur3, mem3) # Output spiking layer\n",
        "\n",
        "            accumulated_features += mem3\n",
        "\n",
        "        return accumulated_features / self.num_steps\n",
        "\n",
        "\n",
        "# --- 4. Meta-Learning Prototypical Network Logic ---\n",
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "    \"\"\"Calculates Euclidean distance between two tensors.\"\"\"\n",
        "    return torch.pow(x1 - x2, 2).sum(dim=1).sqrt()\n",
        "\n",
        "def prototypical_loss(input_features, target_classes, prototypes):\n",
        "    \"\"\"\n",
        "    Computes the prototypical network loss.\n",
        "    input_features: features of query set examples\n",
        "    target_classes: true classes of query set examples\n",
        "    prototypes: dictionary of {class_idx: prototype_vector}\n",
        "    \"\"\"\n",
        "    unique_classes_in_task = sorted(list(prototypes.keys()))\n",
        "    class_to_idx_map = {cls: i for i, cls in enumerate(unique_classes_in_task)}\n",
        "    mapped_target_classes = torch.tensor([class_to_idx_map[cls.item()] for cls in target_classes]).long().to(device)\n",
        "\n",
        "\n",
        "    distances = []\n",
        "    for class_label in unique_classes_in_task:\n",
        "        dist_to_prototype = euclidean_distance(input_features, prototypes[class_label].unsqueeze(0))\n",
        "        distances.append(dist_to_prototype.unsqueeze(1))\n",
        "\n",
        "    logits = -torch.cat(distances, dim=1)\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(logits, mapped_target_classes)\n",
        "    return loss, logits\n",
        "\n",
        "\n",
        "def calculate_accuracy(logits, target_classes, prototypes):\n",
        "    \"\"\"\n",
        "    Calculates the accuracy of predictions.\n",
        "    \"\"\"\n",
        "    unique_classes_in_task = sorted(list(prototypes.keys()))\n",
        "    class_to_idx_map = {cls: i for i, cls in enumerate(unique_classes_in_task)}\n",
        "    mapped_target_classes = torch.tensor([class_to_idx_map[cls.item()] for cls in target_classes]).long().to(device)\n",
        "\n",
        "    predicted_classes = torch.argmax(logits, dim=1)\n",
        "    correct_predictions = (predicted_classes == mapped_target_classes).sum().item()\n",
        "    accuracy = correct_predictions / len(target_classes)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# --- 5. Training and Evaluation Loop ---\n",
        "\n",
        "def train_meta_model(model, optimizer, train_dataset, num_tasks):\n",
        "    \"\"\"Meta-trains the SNN feature extractor.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    print(\"\\n--- Starting Meta-Training ---\")\n",
        "    for i in range(1, num_tasks + 1):\n",
        "        task_batch = train_dataset.get_task_batch(NUM_CLASSES_PER_TASK, N_SHOT, N_QUERY, num_tasks_in_batch=1)\n",
        "        task = task_batch[0]\n",
        "\n",
        "        support_images, support_labels = task['support_set']\n",
        "        query_images, query_labels = task['query_set']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        support_features = model(support_images)\n",
        "\n",
        "        grouped_support_features = defaultdict(list)\n",
        "        for j, label in enumerate(support_labels):\n",
        "            grouped_support_features[label.item()].append(support_features[j])\n",
        "\n",
        "        prototypes = {}\n",
        "        for class_label, features_list in grouped_support_features.items():\n",
        "            prototypes[class_label] = torch.stack(features_list).mean(dim=0)\n",
        "\n",
        "        query_features = model(query_images)\n",
        "\n",
        "        loss, logits = prototypical_loss(query_features, query_labels, prototypes)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = calculate_accuracy(logits, query_labels, prototypes)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_accuracy += acc\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            avg_loss = total_loss / i\n",
        "            avg_acc = total_accuracy / i\n",
        "            print(f\"Task {i}/{num_tasks} | Loss: {avg_loss:.4f} | Accuracy: {avg_acc*100:.2f}%\")\n",
        "\n",
        "    avg_loss_final = total_loss / num_tasks\n",
        "    avg_acc_final = total_accuracy / num_tasks\n",
        "    print(f\"\\nMeta-Training Complete. Avg Loss: {avg_loss_final:.4f} | Avg Accuracy: {avg_acc_final*100:.2f}%\")\n",
        "    return avg_loss_final, avg_acc_final\n",
        "\n",
        "\n",
        "def test_meta_model(model, test_dataset, num_tasks):\n",
        "    \"\"\"Evaluates the SNN feature extractor on unseen meta-test tasks.\"\"\"\n",
        "    model.eval()\n",
        "    total_accuracy = 0\n",
        "    print(\"\\n--- Starting Meta-Testing ---\")\n",
        "    with torch.no_grad():\n",
        "        for i in range(1, num_tasks + 1):\n",
        "            task_batch = test_dataset.get_task_batch(NUM_CLASSES_PER_TASK, N_SHOT, N_QUERY, num_tasks_in_batch=1)\n",
        "            task = task_batch[0]\n",
        "\n",
        "            support_images, support_labels = task['support_set']\n",
        "            query_images, query_labels = task['query_set']\n",
        "\n",
        "            support_features = model(support_images)\n",
        "\n",
        "            grouped_support_features = defaultdict(list)\n",
        "            for j, label in enumerate(support_labels):\n",
        "                grouped_support_features[label.item()].append(support_features[j])\n",
        "\n",
        "            prototypes = {}\n",
        "            for class_label, features_list in grouped_support_features.items():\n",
        "                prototypes[class_label] = torch.stack(features_list).mean(dim=0)\n",
        "\n",
        "            query_features = model(query_images)\n",
        "\n",
        "            distances = []\n",
        "            unique_classes_in_task = sorted(list(prototypes.keys()))\n",
        "            for class_label in unique_classes_in_task:\n",
        "                dist_to_prototype = euclidean_distance(query_features, prototypes[class_label].unsqueeze(0))\n",
        "                distances.append(dist_to_prototype.unsqueeze(1))\n",
        "            logits = -torch.cat(distances, dim=1)\n",
        "\n",
        "            acc = calculate_accuracy(logits, query_labels, prototypes)\n",
        "            total_accuracy += acc\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                avg_acc = total_accuracy / i\n",
        "                print(f\"Test Task {i}/{num_tasks} | Accuracy: {avg_acc*100:.2f}%\")\n",
        "\n",
        "    avg_acc_final = total_accuracy / num_tasks\n",
        "    print(f\"\\nMeta-Testing Complete. Avg Accuracy: {avg_acc_final*100:.2f}%\")\n",
        "    return avg_acc_final\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Running on device: {device}\")\n",
        "\n",
        "    snn_model = SNNFeatureExtractor(BETA, SPIKE_GRAD_BETA, NUM_STEPS).to(device)\n",
        "    optimizer = torch.optim.Adam(snn_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    train_meta_model(snn_model, optimizer, train_dataset, NUM_META_TRAIN_TASKS)\n",
        "\n",
        "    test_meta_model(snn_model, test_dataset, NUM_META_TEST_TASKS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a47b0479a694dc88e4e24a63694af7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19fdd4cb0721478499d0f8cec4bdc310": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24acb4fe799645568f1ef38721a860bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0e1a577e944241bcd585d1aca3e231",
            "placeholder": "​",
            "style": "IPY_MODEL_b0d0d0a478ad4e10a40b28d0c6b54146",
            "value": " 1011894272/? [00:17&lt;00:00, 84835213.42it/s]"
          }
        },
        "2c0e0b1e54ba4949afaa3dfed8872273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3699f65e94014c9d83cd9ab7d5c6eef6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5528ebef5d4f6db3f9f68a5625fab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4f329bffa24dd98f98fa3ba7b9b51b",
            "placeholder": "​",
            "style": "IPY_MODEL_5d2f0cc7c8b540d39865af53a8c24193",
            "value": ""
          }
        },
        "513f3a2a3f314666913b1d4066757da0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ccc4f319c74918ad301e41d4b01a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5313a7f5d97c42509fec571283821a41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b803c4395444d639a08999970a5a42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c5528ebef5d4f6db3f9f68a5625fab3",
              "IPY_MODEL_b5072050079d4e6ca576dc1a4098111a",
              "IPY_MODEL_24acb4fe799645568f1ef38721a860bf"
            ],
            "layout": "IPY_MODEL_0a47b0479a694dc88e4e24a63694af7f"
          }
        },
        "5d2f0cc7c8b540d39865af53a8c24193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f4f329bffa24dd98f98fa3ba7b9b51b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c8eb82204a4514804853d28d980b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "745121e8201b4fbb90b6373a3ead3ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "758823e27cc24763aef595d8974ee947": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fdd4cb0721478499d0f8cec4bdc310",
            "max": 169674850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72c8eb82204a4514804853d28d980b74",
            "value": 169674850
          }
        },
        "85c0aab1c3ad43e1a349aef7740ac161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513f3a2a3f314666913b1d4066757da0",
            "placeholder": "​",
            "style": "IPY_MODEL_2c0e0b1e54ba4949afaa3dfed8872273",
            "value": ""
          }
        },
        "872265ce411b4abf816095a70c4e604a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4c17ae1eba34263ab6732ca479fddd3",
            "placeholder": "​",
            "style": "IPY_MODEL_52ccc4f319c74918ad301e41d4b01a37",
            "value": " 169675776/? [00:01&lt;00:00, 96182287.69it/s]"
          }
        },
        "9a0e1a577e944241bcd585d1aca3e231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d0d0a478ad4e10a40b28d0c6b54146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5072050079d4e6ca576dc1a4098111a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5313a7f5d97c42509fec571283821a41",
            "max": 1011893601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_745121e8201b4fbb90b6373a3ead3ea4",
            "value": 1011893601
          }
        },
        "d4c17ae1eba34263ab6732ca479fddd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53f11ba0897465396a099ce1ab81fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c0aab1c3ad43e1a349aef7740ac161",
              "IPY_MODEL_758823e27cc24763aef595d8974ee947",
              "IPY_MODEL_872265ce411b4abf816095a70c4e604a"
            ],
            "layout": "IPY_MODEL_3699f65e94014c9d83cd9ab7d5c6eef6"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}